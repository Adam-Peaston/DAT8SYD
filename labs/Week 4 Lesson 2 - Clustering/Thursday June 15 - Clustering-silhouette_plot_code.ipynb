{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - Kmeans\n",
    "1. Simple walk through example\n",
    "2. Analysing songs\n",
    "3. Cluster Validation\n",
    "4. Kmeans Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Part 1. KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# EXERCISE: Compute the centoid of the following data\n",
    "#           [2, 5], [4, 4], [3, 3]\n",
    "# ------------------------------------------\n",
    "\n",
    "d = np.array([[2, 5], [4, 4], [3, 3]])\n",
    "x, y = d.mean(axis=0)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import iris data\n",
    "iris = datasets.load_iris()\n",
    "d = iris.data\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run KMeans using 3 clusters\n",
    "est = KMeans(n_clusters=3, init='random')\n",
    "est.fit(d)\n",
    "y_kmeans = est.predict(d)\n",
    "\n",
    "colors = np.array(['#FF0054','#FBD039','#23C2BC'])\n",
    "plt.figure()\n",
    "plt.scatter(d[:, 2], d[:, 0], c=colors[y_kmeans], s=50)\n",
    "plt.xlabel(iris.feature_names[2])\n",
    "plt.ylabel(iris.feature_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Find the centers and plot them \n",
    "#     on the same graph.\n",
    "# ------------------------------------------\n",
    "\n",
    "centers = est.cluster_centers_\n",
    "plt.figure()\n",
    "plt.scatter(d[:, 2], d[:, 0], c=colors[y_kmeans], s=50)\n",
    "plt.xlabel(iris.feature_names[2])\n",
    "plt.ylabel(iris.feature_names[0])\n",
    "plt.scatter(centers[:, 2], centers[:, 0], c='k', linewidths=3,\n",
    "            marker='+', s=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Option #1: Scatter Plot Grid\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.suptitle('Scatter Plot Grid',  fontsize=14)\n",
    "# Upper Left\n",
    "plt.subplot(221)\n",
    "plt.scatter(d[:,2], d[:,0], c = colors[y_kmeans])\n",
    "plt.ylabel(iris.feature_names[0])\n",
    "\n",
    "# Upper Right\n",
    "plt.subplot(222)\n",
    "plt.scatter(d[:,3], d[:,0], c = colors[y_kmeans])\n",
    "\n",
    "# Lower Left\n",
    "plt.subplot(223)\n",
    "plt.scatter(d[:,2], d[:,1], c = colors[y_kmeans])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "plt.xlabel(iris.feature_names[2])\n",
    "\n",
    "# Lower Right\n",
    "plt.subplot(224)\n",
    "plt.scatter(d[:,3], d[:,1], c = colors[y_kmeans])\n",
    "plt.xlabel(iris.feature_names[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.suptitle('3d plot', fontsize=15)\n",
    "ax = Axes3D(plt.figure(figsize=(10, 9)), rect=[.01, 0, 0.95, 1], elev=30, azim=134)\n",
    "ax.scatter(d[:,0], d[:,1], d[:,2], c = colors[y_kmeans], s=120)\n",
    "ax.set_xlabel('Sepal Width')\n",
    "ax.set_ylabel('Sepal Length')\n",
    "ax.set_zlabel('Petal Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import parallel_coordinates\n",
    "\n",
    "features = [name[:-5].title().replace(' ', '') for name in iris.feature_names]\n",
    "iris_df = pd.DataFrame(iris.data, columns = features)\n",
    "iris_df['Name'] = iris.target_names[iris.target]\n",
    "parallel_coordinates(frame=iris_df, class_column='Name', \n",
    "                     color=('#FF0054', '#FBD039', '#23C2BC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "DETERMINING THE NUMBER OF CLUSTERS\n",
    "How do you choose k? There isn't a bright line, but we can evaluate \n",
    "performance metrics such as the silhouette coefficient and within sum of \n",
    "squared errors across values of k.\n",
    "\n",
    "scikit-learn Clustering metrics documentation:\n",
    "http://scikit-learn.org/stable/modules/classes.html#clustering-metrics\n",
    "'''\n",
    "\n",
    "# Create a bunch of different models\n",
    "k_rng = range(1,15)\n",
    "est = [KMeans(n_clusters = k).fit(d) for k in k_rng]\n",
    "\n",
    "#================================\n",
    "# Option 1: Silhouette Coefficient\n",
    "# Generally want SC to be closer to 1, while also minimizing k\n",
    "\n",
    "from sklearn import metrics\n",
    "silhouette_scores = [metrics.silhouette_score(d, e.labels_, metric='euclidean') for e in est[1:]]\n",
    "\n",
    "silhouette_scores\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(7, 8))\n",
    "plt.subplot(211)\n",
    "plt.title('Using the elbow method to inform k choice')\n",
    "plt.plot(k_rng[1:], silhouette_scores, 'b*-')\n",
    "plt.xlim([1,15])\n",
    "plt.grid(True)\n",
    "plt.ylabel('Silhouette Coefficient')\n",
    "plt.plot(3,silhouette_scores[1], 'o', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Option 2: Within Sum of Squares (a.k.a., inertia)\n",
    "# Generally want to minimize WSS, while also minimizing k\n",
    "\n",
    "within_sum_squares = [e.inertia_ for e in est]\n",
    "\n",
    "within_sum_squares\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(k_rng, within_sum_squares, 'b*-')\n",
    "plt.xlim([1,15])\n",
    "plt.grid(True)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Within Sum of Squares')\n",
    "plt.plot(3,within_sum_squares[2], 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Part 2. Analysing songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# explore\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform clustering with 4 clusters\n",
    "song_cluster = KMeans(n_clusters=4, init='random')\n",
    "song_cluster.fit(df.drop('name', axis=1))\n",
    "y_kmeans = song_cluster.predict(df.drop('name', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Silhouette metric to measure the cluster quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhoute is a measure of cluster cohesiveness. See the sklearn code for a plot:\n",
    "http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mild rhythmic syncopation', 0.28965517241379302), ('extensive vamping', 0.27586206896551718), ('punk influences', 0.25517241379310351), ('repetitive melodic phrasing', 0.2482758620689654), ('electric rhythm guitars', 0.20689655172413796)]\n",
      "[('a clear focus on recording studio production', 0.84210526315789447), ('emphasis on instrumental arranging', 0.52631578947368429), ('mild rhythmic syncopation', 0.52631578947368429), ('intricate melodic phrasing', 0.47368421052631571), ('prominent use of synth', 0.47368421052631571)]\n",
      "[('electronica influences', 0.88235294117647034), ('consistent rhyme patterns', 0.82352941176470607), ('syncopated beats', 0.76470588235294101), ('hardcore rap influence', 0.64705882352941158), ('the use of chordal patterning', 0.58823529411764719)]\n",
      "[('use of modal harmonies', 0.68518518518518523), ('synth riffs', 0.64814814814814792), ('prevalent use of groove', 0.592592592592593), ('a highly synthetic sonority', 0.59259259259259245), ('effected synths', 0.59259259259259245)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get info on one cluster\n",
    "for cluster_in_question in range(0,4):\n",
    "    # get center of cluster\n",
    "    \"centroid\", song_cluster.cluster_centers_[cluster_in_question]\n",
    "    # grab songs in dataframe that belong to this cluster\n",
    "    songs = df[np.where(y_kmeans == cluster_in_question, True, False)]['name']\n",
    "    # look at top five qualities in cluster\n",
    "    print (sorted(zip(df.columns[1:], song_cluster.cluster_centers_[cluster_in_question]), key=lambda x:x[1], reverse=True)[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10709809035942083"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.silhouette_score(df.drop('name',axis=1), song_cluster.labels_, metric='euclidean')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform k means with up to 15 clusters\n",
    "# similar to grid search, just using a list\n",
    "# comprehension\n",
    "k_rng = range(1,15)\n",
    "est = [KMeans(n_clusters = k).fit(df.drop('name',axis=1)) for k in k_rng]\n",
    "\n",
    "# What do these clusters look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the clusters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write code to plot the clusters\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.213784731135\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7287d3ccd72c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0my_upper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_lower\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize_cluster_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         ax1.fill_betweenx(np.arange(y_lower, y_upper),\n\u001b[1;32m     45\u001b[0m                           \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mith_cluster_silhouette_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBkAAAGfCAYAAAAargqQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11875e828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "range_n_clusters = k_rng[1:10]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # create plot object, \n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(18, 7)\n",
    "    \n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    #ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "\n",
    "    #clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    clusterer = est[n_clusters]\n",
    "    cluster_labels = clusterer.fit_predict(df.drop('name',axis=1))\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = metrics.silhouette_score(df.drop('name',axis=1), cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = metrics.silhouette_samples(df.drop('name',axis=1), cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    \n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "          \"with n_clusters = %d\" % n_clusters), fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "clusterer = est[1]\n",
    "cluster_labels = clusterer.fit_predict(df.drop('name',axis=1))\n",
    "\n",
    "# The silhouette_score gives the average value for all the samples.\n",
    "# This gives a perspective into the density and separation of the formed\n",
    "# clusters\n",
    "silhouette_avg = silhouette_score(df.drop('name',axis=1), cluster_labels)\n",
    "print(\"For n_clusters =\", n_clusters,\n",
    "      \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "# Compute the silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(df.drop('name',axis=1), cluster_labels)\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters):\n",
    "    # Aggregate the silhouette scores for samples belonging to\n",
    "    # cluster i, and sort them\n",
    "    ith_cluster_silhouette_values = \\\n",
    "        sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = cm.spectral(float(i) / n_clusters)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                      0, ith_cluster_silhouette_values,\n",
    "                      facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "    # Label the silhouette plots with their cluster numbers at the middle\n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "    # Compute the new y_lower for next plot\n",
    "    y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "range_n_clusters = k_rng[0:12]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    #fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    #fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    \n",
    "    #clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    clusterer = est[n_clusters]\n",
    "    cluster_labels = clusterer.fit_predict(df.drop('name',axis=1))\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(df.drop('name',axis=1), cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(df.drop('name',axis=1), cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    #ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    #ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    #ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "'''\n",
    "K = 2\n",
    "'''\n",
    "\n",
    "# Generate and Plot Dummy Data for k = 2\n",
    "centres = [[2, 0.75], [0, 0]]\n",
    "X0, labels0_true = make_blobs(n_samples=300, centers=centres[0], cluster_std=[[0.2,0.2]])\n",
    "X1, labels1_true = make_blobs(n_samples=300, centers=centres[1], cluster_std=[[0.2,0.2]])\n",
    "X = np.concatenate((X0,X1))\n",
    "labels_true = np.concatenate((labels0_true,labels1_true+1))\n",
    "colors = np.array(['#FF0054','#FBD039'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.suptitle('Cluster Validation Evaluation', fontsize=15)\n",
    "plt.subplot(331)\n",
    "plt.text(-0.5, 1.5, 'k=2', fontsize=14)\n",
    "for k, col in zip(range(2), colors):\n",
    "    my_members = labels_true == k\n",
    "    cluster_center = centres[k]\n",
    "    plt.scatter(X[my_members, 0], X[my_members, 1], c=col, marker='o',s=20) \n",
    "    plt.scatter(cluster_center[0], cluster_center[1], c=col, marker='o', s=200)\n",
    "plt.axis('equal')\n",
    "plt.title('Data with truth labels')\n",
    "plt.ylabel('y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate Silhouette Scores for different values of K, highlighting k = 2\n",
    "k_rng = range(1,15)\n",
    "est = [KMeans(n_clusters = k).fit(X) for k in k_rng]\n",
    "silhouette_score = [metrics.silhouette_score(X, e.labels_, metric='euclidean') for e in est[1:]]\n",
    "plt.plot(k_rng[1:], silhouette_score, 'b*-')\n",
    "plt.xlim([1,15])\n",
    "plt.grid(True)\n",
    "plt.title('Silhouette Coefficient')\n",
    "plt.plot(2,silhouette_score[0], 'o', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Do you think k=2 is a good value for the silhouette coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the within sum of squared errors for different values of K, highlighting k = 2\n",
    "within_sum_squares = [e.inertia_ for e in est]\n",
    "plt.plot(k_rng, within_sum_squares, 'b*-')\n",
    "plt.xlim([1,15])\n",
    "plt.grid(True)\n",
    "plt.title('Within Sum of Squared Errors')\n",
    "plt.plot(2,within_sum_squares[1], 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Do you think this is a good value for within sum of squares? If not, which value of k would be better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now perform K-means clustering for K=3, and plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "K = 3\n",
    "'''\n",
    "\n",
    "# Generate and Plot Dummy Data for k = 3\n",
    "centres = [[2, 0.75], [1, -0.75], [0, 0]]\n",
    "X0, labels0_true = make_blobs(n_samples=300, centers=centres[0], cluster_std=[[0.2,0.2]])\n",
    "X1, labels1_true = make_blobs(n_samples=300, centers=centres[1], cluster_std=[[0.2,0.2]])\n",
    "X2, labels2_true = make_blobs(n_samples=300, centers=centres[2], cluster_std=[[0.2,0.2]])\n",
    "X = np.concatenate((X0,X1,X2))\n",
    "labels_true = np.concatenate((labels0_true,labels1_true+1,labels2_true+2))\n",
    "colors = np.array(['#FF0054','#FBD039','#23C2BC'])\n",
    "plt.text(-1, 1.5, 'k=3', fontsize=14)\n",
    "for k, col in zip(range(3), colors):\n",
    "    my_members = labels_true == k\n",
    "    cluster_center = centres[k]\n",
    "    plt.scatter(X[my_members, 0], X[my_members, 1], c=col, marker='o',s=20) \n",
    "    plt.scatter(cluster_center[0], cluster_center[1], c=col, marker='o', s=200)\n",
    "plt.axis('equal')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate Silhouette Scores for different values of K, highlighting k = 3\n",
    "est = [KMeans(n_clusters = k).fit(X) for k in k_rng]\n",
    "silhouette_score = [metrics.silhouette_score(X, e.labels_, metric='euclidean') for e in est[1:]]\n",
    "plt.plot(k_rng[1:], silhouette_score, 'b*-')\n",
    "plt.xlim([1,15])\n",
    "plt.grid(True)\n",
    "plt.plot(3,silhouette_score[1], 'o', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the within sum of squared errors for different values of K, highlighting k = 3\n",
    "within_sum_squares = [e.inertia_ for e in est]\n",
    "plt.plot(k_rng, within_sum_squares, 'b*-')\n",
    "plt.xlim([1,15])\n",
    "plt.grid(True)\n",
    "plt.plot(3,within_sum_squares[2], 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate and Plot Dummy Data for k = 5\n",
    "centres = [[2, 0.75], [1, -0.75], [0, 0], [0.5, 1.5], [3, -0.5]]\n",
    "X0, labels0_true = make_blobs(n_samples=300, centers=centres[0], cluster_std=[[0.2,0.2]])\n",
    "X1, labels1_true = make_blobs(n_samples=300, centers=centres[1], cluster_std=[[0.2,0.2]])\n",
    "X2, labels2_true = make_blobs(n_samples=300, centers=centres[2], cluster_std=[[0.2,0.2]])\n",
    "X3, labels3_true = make_blobs(n_samples=300, centers=centres[3], cluster_std=[[0.2,0.2]])\n",
    "X4, labels4_true = make_blobs(n_samples=300, centers=centres[4], cluster_std=[[0.2,0.2]])\n",
    "X = np.concatenate((X0,X1,X2,X3,X4))\n",
    "labels_true = np.concatenate((labels0_true,labels1_true+1,labels2_true+2,\n",
    "                              labels3_true+3,labels4_true+4))\n",
    "colors = np.array(['#FF0054','#FBD039','#23C2BC', '#650A34', '#808080'])\n",
    "plt.text(-1, 2, 'k=5', fontsize=14)\n",
    "for k, col in zip(range(5), colors):\n",
    "    my_members = labels_true == k\n",
    "    cluster_center = centres[k]\n",
    "    plt.scatter(X[my_members, 0], X[my_members, 1], c=col, marker='o',s=20) \n",
    "    plt.scatter(cluster_center[0], cluster_center[1], c=col, marker='o', s=200)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate Silhouette Scores for different values of K, highlighting k = 5\n",
    "est = [KMeans(n_clusters = k).fit(X) for k in k_rng]\n",
    "silhouette_score = [metrics.silhouette_score(X, e.labels_, metric='euclidean') for e in est[1:]]\n",
    "plt.plot(k_rng[1:], silhouette_score, 'b*-')\n",
    "plt.xlim([1,15])\n",
    "plt.grid(True)\n",
    "plt.xlabel('k')\n",
    "plt.plot(5,silhouette_score[3], 'o', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the within sum of squared errors for different values of K, highlighting k = 5\n",
    "within_sum_squares = [e.inertia_ for e in est]\n",
    "plt.plot(k_rng, within_sum_squares, 'b*-')\n",
    "plt.xlim([1,15])\n",
    "plt.grid(True)\n",
    "plt.xlabel('k')\n",
    "plt.plot(5,within_sum_squares[4], 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kmeans Limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NOTES ON LIMITATIONS OF K-MEANS CLUSTERING\n",
    "\n",
    "Adapted from Bart Baddely's 2014 PyData Presentation:\n",
    "http://nbviewer.ipython.org/github/BartBaddeley/PyDataTalk-2014/blob/master/PyDataTalk.ipynb\n",
    "\n",
    "Agenda: \n",
    "1) K-means might not work when dimensions have different scales\n",
    "2) K-means might not work for non-spherical shapes\n",
    "3) K-means might not work for clusters of different sizes\n",
    "'''\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs, make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "'''\n",
    "1) DIMENSIONS WITH DIFFERENT SCALES\n",
    "'''\n",
    "\n",
    "# Generate data with differing variances\n",
    "np.random.seed(0)\n",
    "\n",
    "centres = [[1, 0.75], [1, -0.75], [0, 0]]\n",
    "\n",
    "X0, labels0_true = make_blobs(n_samples=300, centers=centres[0], cluster_std=[[0.6,0.1]])\n",
    "X1, labels1_true = make_blobs(n_samples=300, centers=centres[1], cluster_std=[[0.6,0.1]])\n",
    "X2, labels2_true = make_blobs(n_samples=300, centers=centres[2], cluster_std=[[0.6,0.1]])\n",
    "X = np.concatenate((X0,X1,X2))\n",
    "labels_true = np.concatenate((labels0_true,labels1_true+1,labels2_true+2))\n",
    "\n",
    "colors = np.array(['#FF0054','#FBD039','#23C2BC'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.suptitle('Dimensions with Different Scales', fontsize=15)\n",
    "for k, col in zip(range(3), colors):\n",
    "    my_members = labels_true == k\n",
    "    cluster_center = centres[k]\n",
    "    plt.scatter(X[my_members, 0], X[my_members, 1], c=col, marker='o',s=20) \n",
    "    plt.scatter(cluster_center[0], cluster_center[1], c=col, marker='o', s=200)\n",
    "plt.axis('equal')\n",
    "plt.title('Original data')\n",
    "\n",
    "# Compute clustering with 3 Clusters\n",
    "k_means_3 = KMeans(init='k-means++', n_clusters=3, n_init=10)\n",
    "k_means_3.fit(X)\n",
    "k_means_3_labels = k_means_3.labels_\n",
    "k_means_3_cluster_centres = k_means_3.cluster_centers_\n",
    "\n",
    "# Plot result\n",
    "distance = euclidean_distances(k_means_3_cluster_centres,\n",
    "                               centres,\n",
    "                               squared=True)\n",
    "order = distance.argmin(axis=0)\n",
    "for k, col in zip(range(3), colors):              \n",
    "    my_members = k_means_3_labels == order[k]\n",
    "    plt.scatter(X[my_members, 0], X[my_members, 1],c=col, marker='o', s=20)           \n",
    "    cluster_center = k_means_3_cluster_centres[order[k]]\n",
    "    plt.scatter(cluster_center[0], cluster_center[1], marker = 'o', c=col, s=200, alpha=0.8)            \n",
    "plt.axis('equal')\n",
    "plt.title('KMeans 3')\n",
    "\n",
    "'''\n",
    "#2: NON-SPHERICAL SHAPES\n",
    "'''\n",
    "\n",
    "[X, true_labels] = make_moons(n_samples=1000, noise=.05)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.suptitle('Non-Spherical Shapes', fontsize=15)\n",
    "for k, col in zip(range(2), colors):\n",
    "    my_members = true_labels == k\n",
    "    plt.scatter(X[my_members, 0], X[my_members, 1], c=col, marker='o', s=20)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.title('Original Data') \n",
    "    \n",
    "# Compute clustering with 2 Clusters\n",
    "k_means_2 = KMeans(init='k-means++', n_clusters=2, n_init=10)\n",
    "k_means_2.fit(X)\n",
    "k_means_2_labels = k_means_2.labels_\n",
    "k_means_2_cluster_centers = k_means_2.cluster_centers_\n",
    "\n",
    "for k, col in zip(range(2), colors):           \n",
    "    my_members = k_means_2_labels == k\n",
    "    plt.scatter(X[my_members, 0], X[my_members, 1],c=col, marker='o', s=20)     \n",
    "    cluster_center = k_means_2_cluster_centers[k]\n",
    "    plt.scatter(cluster_center[0], cluster_center[1], marker = 'o', c=col, s=200, alpha=0.8) \n",
    "plt.axis('equal')\n",
    "plt.title('KMeans 2')\n",
    "\n",
    "'''\n",
    "#3: CLUSTERS OF DIFFERENT SIZES\n",
    "'''\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "centres = [[-1, 0], [1, 0], [3, 0]]\n",
    "\n",
    "X0, labels0_true = make_blobs(n_samples=100, centers=centres[0], cluster_std=[[0.2,0.2]])\n",
    "X1, labels1_true = make_blobs(n_samples=400, centers=centres[1], cluster_std=[[0.6,0.6]])\n",
    "X2, labels2_true = make_blobs(n_samples=100, centers=centres[2], cluster_std=[[0.2,0.2]])\n",
    "X = np.concatenate((X0,X1,X2))\n",
    "labels_true = np.concatenate((labels0_true,labels1_true+1,labels2_true+2))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.suptitle('Clusters of Different Sizes', fontsize=15)\n",
    "for k, col in zip(range(3), colors):\n",
    "    my_members = labels_true == k\n",
    "    cluster_center = centres[k]\n",
    "    plt.scatter(X[my_members, 0], X[my_members, 1], c=col, marker='o',s=20) \n",
    "    plt.scatter(cluster_center[0], cluster_center[1], c=col, marker='o', s=200)\n",
    "plt.axis('equal')\n",
    "plt.title('Original data')\n",
    "\n",
    "# Compute clustering with 3 Clusters\n",
    "k_means_3 = KMeans(init='k-means++', n_clusters=3, n_init=10)\n",
    "k_means_3.fit(X)\n",
    "k_means_3_labels = k_means_3.labels_\n",
    "k_means_3_cluster_centres = k_means_3.cluster_centers_\n",
    "\n",
    "# Plot result\n",
    "distance = euclidean_distances(k_means_3_cluster_centres,\n",
    "                               centres,\n",
    "                               squared=True)\n",
    "order = distance.argmin(axis=0)\n",
    "for k, col in zip(range(3), colors):              \n",
    "    my_members = k_means_3_labels == order[k]\n",
    "    plt.scatter(X[my_members, 0], X[my_members, 1],c=col, marker='o', s=20)           \n",
    "    cluster_center = k_means_3_cluster_centres[order[k]]\n",
    "    plt.scatter(cluster_center[0], cluster_center[1], marker = 'o', c=col, s=200, alpha=0.8)            \n",
    "plt.axis('equal')\n",
    "plt.title('KMeans 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Apply DBSCAN\n",
    "\n",
    "For the data sets generated in point 4, apply DBSCAN and plot the results to see how well it does on each set, compared to K-Means\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
